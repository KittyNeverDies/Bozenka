import logging
import os

from aiogram import F
from aiogram.filters.callback_data import CallbackData
from aiogram.fsm.context import FSMContext
from aiogram.types import Message, InlineKeyboardMarkup, InlineKeyboardButton, CallbackQuery
from aiogram.utils.keyboard import InlineKeyboardBuilder
from gpt4all import GPT4All

from bozenka.generative.providers.main import BasicAiGenerativeProvider
from bozenka.instances.telegram.utils.callbacks_factory import GptStop, GptCategory, GptBackMenu, Gpt4AllSelect, \
    Gpt4AllModel
from bozenka.instances.telegram.utils.delete import delete_keyboard
from bozenka.instances.telegram.utils.simpler import AIGeneration


model_path = os.getcwd() + "\\model\\"


class DeleteMenu(CallbackData, prefix="delete"):
    """
       Callback with information to delete message
    """
    user_id_clicked: int


class TextToText(CallbackData, prefix='text2text'):
    category_name: str
    user_id: int


def check(model_filename: str) -> bool:
    """
    Checking & downloading our gpt4all models
    Returns True if it's already downloaded
    Returns False if it's not downloaded
    :param model_filename: File name of gpt4all model
    :return: Does it exist
    """
    print(os.path.exists("models\\" + model_filename))
    return os.path.exists("models\\" + model_filename)


# Gpt4All related keyboards
def generate_gpt4all_page(user_id: int) -> InlineKeyboardMarkup:
    """
    Generating list of GPT4All models.
    :param user_id:
    :return:
    """
    models = GPT4All.list_models()

    builder = InlineKeyboardBuilder()

    for model in models:
        builder.row(InlineKeyboardButton(
            text=model["name"],
            callback_data=Gpt4AllModel(user_id=str(user_id), index=str(models.index(model))).pack())
        )
    builder.row(InlineKeyboardButton(text="üîô –í–µ—Ä–Ω—É—Ç—å—Å—è –∫ —Å–ø–∏—Å–∫—É",
                                     callback_data=GptBackMenu(user_id=user_id, back_to="g4fcategory").pack()))
    builder.row(InlineKeyboardButton(text="–°–ø–∞—Å–∏–±–æ, –Ω–µ –Ω–∞–¥–æ ‚ùå",
                                     callback_data=GptStop(user_id=str(user_id)).pack()))
    return builder.as_markup()


def gpt4all_model_menu(user_id: int, index: int) -> InlineKeyboardMarkup:
    """
    Generating menu for selection on of GPT4ALL models
    :param user_id:
    :param index:
    """
    kb = InlineKeyboardMarkup(inline_keyboard=[
        [InlineKeyboardButton(text="–í—ã–±—Ä–∞—Ç—å ‚úÖ",
                              callback_data=Gpt4AllSelect(user_id=user_id, index=str(index)).pack())],
        [InlineKeyboardButton(text="üîô –í–µ—Ä–Ω—É—Ç—å—Å—è –∫ —Å–ø–∏—Å–∫—É",
                              callback_data=GptBackMenu(user_id=user_id, back_to="g4amodels").pack())],
        [InlineKeyboardButton(text="–°–ø–∞—Å–∏–±–æ, –Ω–µ –Ω–∞–¥–æ ‚ùå",
                              callback_data=GptStop(user_id=str(user_id)).pack())]
    ])
    return kb


def text_response_keyboard(user_id: int) -> InlineKeyboardMarkup:
    """
    Generating menu for response from GPT
    :param user_id:
    :return:
    """
    kb = InlineKeyboardMarkup(inline_keyboard=[
        [InlineKeyboardButton(text="–°–ø–∞—Å–∏–±–æ ‚úÖ", callback_data=DeleteMenu(user_id_clicked=str(user_id)).pack())],
        [InlineKeyboardButton(text="–ó–∞–≤–µ—Ä—à–∏—Ç—å –¥–∏–∞–ª–æ–≥ üö´", callback_data=GptStop(user_id=str(user_id)).pack())]
    ])
    return kb


class Gpt4All(BasicAiGenerativeProvider):
    model_path = os.getcwd() + "\\model\\"

    @staticmethod
    async def generate_telegram(msg: Message, state: FSMContext):
        """
        Generates response for telegram user
        :param msg: Telegram message object
        :param state: FSMContext aiogram object
        :return: None
        """

        models = GPT4All.list_models()
        answer = ""
        data = await state.get_data()

        main_msg = await msg.answer("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞ –ø–æ–¥–æ–∂–¥–∏—Ç–µ, –º—ã –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –≤–∞–º –æ—Ç–≤–µ—Ç ‚è∞\n"
                                    "–ï—Å–ª–∏ —á—Ç–æ-—Ç–æ –ø–æ–π–¥–µ—Ç –Ω–µ —Ç–∞–∫, –º—ã –≤–∞–º —Å–æ–æ–±—â–∏–º üëå",
                                    reply_markup=text_response_keyboard(user_id=msg.from_user.id))

        if not check(models[data["model"]]["filename"]):
            main_msg = await main_msg.edit_text(main_msg.text + "\n–ü–æ–¥–æ–∂–¥–∏—Ç–µ –ø–æ–∂–∞–ª—É—Å—Ç–∞, –º—ã —Å–∫–∞—á–∏–≤–∞–µ–º –º–æ–¥–µ–ª—å...",
                                                reply_markup=main_msg.reply_markup)

        try:
            # Setting Gpt4All model
            model = GPT4All(model_name=models[data["model"]]["filename"],
                            model_path=model_path,
                            allow_download=True)
            # Setting our chat session if exist
            model.current_chat_session = [] if not data.get("chat_history") else data["chat_history"]
            # Generating answer
            with model.chat_session():
                answer = model.generate(msg.text)
                await state.update_data(chat_history=model.current_chat_session)

        except Exception as S:
            answer = "–ü—Ä–æ—Å—Ç–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ üòî\n–ï—Å–ª–∏ —ç—Ç–æ –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç—Å—è, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ /cancel –∏–ª–∏ –∫–Ω–æ–∫–ø—É –ø–æ–¥ —Å–æ–æ–±—â–µ–Ω–∏–µ–º."
            logging.log(msg=f"Get an exception for generating answer={S}",
                        level=logging.ERROR)
        finally:
            await main_msg.edit_text(answer, reply_markup=text_response_keyboard(user_id=msg.from_user.id))

        await state.set_state(AIGeneration.ready_to_answer)

    @staticmethod
    async def telegram_g4a_handler(call: CallbackQuery, callback_data: TextToText, state: FSMContext) -> None:
        """
        Query, what shows list for gpt4all models
        :param state: FSMContext aiogram class
        :param call: CallbackQuery telegram class
        :param callback_data: GptCategory class
        :return: None
        """
        if callback_data.user_id != call.from_user.id or await state.get_state():
            return

        await state.update_data(category="text2text", name="Gpt4All")

        await state.set_state(AIGeneration.selection)
        await call.message.edit_text("–ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ Gpt4All\n\n"
                                     "–í—Å–µ –º–æ–¥–µ–ª–∏ –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π –±—É–¥—É—Ç —Å–∫–∞—á–∏–≤–∞—Ç—å—Å—è –Ω–∞ —Å–µ—Ä–≤–µ—Ä, –ø–æ —ç—Ç–æ–º—É –≤–∞–º –Ω—É–∂–Ω–æ –±—É–¥–µ—Ç –ø–æ–¥–æ–∂–¥–∞—Ç—å –Ω–µ–∫–æ—Ç–æ—Ä–æ–µ –≤—Ä–µ–º—è –∑–∞–≥—Ä—É–∑–∫–∏\n"
                                     "–ù–µ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –≤–µ–± —Ä–µ—Å—É—Ä—Å–æ–≤, –∫–∞–∫ Gpt4Free, –Ω–æ —Ç—Ä–µ–±—É–µ—Ç –±–æ–ª—å—à–µ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –æ—Ç–≤–µ—Ç–∞ –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ.\n\n"
                                     "–í—ã–±–µ—Ä–∏—Ç–µ –ø–æ–∂–∞–ª—É–π—Å—Ç–∞ –º–æ–¥–µ–ª—å –∏—Å–∫—É—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–µ–∫—Ç–∞ üëæ",
                                     reply_markup=generate_gpt4all_page(user_id=call.from_user.id))

    @staticmethod
    async def telegram_g4a_back_handler(call: CallbackQuery, callback_data: GptCategory, state: FSMContext) -> None:
        """
        Query, what shows list for gpt4all models back
        :param state: FSMContext aiogram class
        :param call: CallbackQuery telegram class
        :param callback_data: GptCategory class
        :return: None
        """
        if callback_data.user_id != call.from_user.id:
            return
        await call.message.edit_text("–ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ Gpt4All\n\n"
                                     "–í—Å–µ –º–æ–¥–µ–ª–∏ –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π –±—É–¥—É—Ç —Å–∫–∞—á–∏–≤–∞—Ç—å—Å—è –Ω–∞ —Å–µ—Ä–≤–µ—Ä, –ø–æ —ç—Ç–æ–º—É –≤–∞–º –Ω—É–∂–Ω–æ –±—É–¥–µ—Ç –ø–æ–¥–æ–∂–¥–∞—Ç—å –Ω–µ–∫–æ—Ç–æ—Ä–æ–µ –≤—Ä–µ–º—è –∑–∞–≥—Ä—É–∑–∫–∏\n"
                                     "–ù–µ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –≤–µ–± —Ä–µ—Å—É—Ä—Å–æ–≤, –∫–∞–∫ Gpt4Free, –Ω–æ —Ç—Ä–µ–±—É–µ—Ç –±–æ–ª—å—à–µ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –æ—Ç–≤–µ—Ç–∞ –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ.\n\n"
                                     "–í—ã–±–µ—Ä–∏—Ç–µ –ø–æ–∂–∞–ª—É–π—Å—Ç–∞ –º–æ–¥–µ–ª—å –∏—Å–∫—É—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–µ–∫—Ç–∞ üëæ",
                                     reply_markup=generate_gpt4all_page(user_id=call.from_user.id))

    @staticmethod
    async def telegram_g4a_infomration_handler(call: CallbackQuery, callback_data: Gpt4AllModel,
                                               state: FSMContext) -> None:
        """
        Query, what show information about clicked gpt4all model from list
        :param state: FSMContext aiogram class
        :param call: CallbackQuery telegram class
        :param callback_data: Gpt4AllModel class
        :return: None
        """
        if callback_data.user_id != call.from_user.id:
            return
        models = GPT4All.list_models()
        name = models[callback_data.index]['name']
        await call.message.edit_text(f"{name}\n\n"
                                     f"–û–±—É—á–µ–Ω–Ω–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ {models[callback_data.index]['parameters']} —Å—Ç—Ä–æ–∫ üë®‚Äçüíª\n"
                                     f"–¢–∏–ø –º–æ–¥–µ–ª–∏: {models[callback_data.index]['type']}\n\n"
                                     f"–ß—Ç–æ–±—ã –≤—ã–±—Ä–∞—Ç—å —ç—Ç–æ –º–æ–¥–µ–ª—å, –Ω–∞–∂–∏–º—Ç–µ –Ω–µ –∫–Ω–æ–ø–∫—É <b>–í—ã–±—Ä–∞—Ç—å</b>\n"
                                     f"–ß—Ç–æ–±—ã –≤–µ—Ä–Ω—É—Ç—å—Å—è –∫ —Å–ø–∏—Å–∫—É –º–æ–¥–µ–ª–µ–π, –Ω–∞–∂–º–∏—Ç–µ –Ω–∞ –∫–Ω–æ–ø–∫—É <b>–í–µ—Ä–Ω—É—Ç—å—Å—è –∫ —Å–ø–∏—Å–∫—É.</b>\n"
                                     f"–ß—Ç–æ–±—ã –æ—Ç–º–µ–Ω–∏—Ç—å –≤—ã–±–æ—Ä, –Ω–∞–∂–º–∏—Ç–µ –Ω–∞ –∫–Ω–æ–ø–∫—É <b>–°–ø–∞—Å–∏–±–æ, –Ω–µ –Ω–∞–¥–æ.</b>\n",
                                     reply_markup=gpt4all_model_menu(user_id=call.from_user.id,
                                                                     index=callback_data.index))

    @staticmethod
    async def telegram_g4a_selected_handler(call: CallbackQuery, callback_data: Gpt4AllSelect,
                                            state: FSMContext) -> None:
        """
        Query, what says about getting ready for question for Gpt4All model
        :param state: FSMContext aiogram class
        :param call: CallbackQuery telegram class
        :param callback_data: Gpt4AllSelect class
        :return: None
        """
        if callback_data.user_id != call.from_user.id:
            return
        await state.update_data(model=callback_data.index)
        await state.set_state(AIGeneration.ready_to_answer)
        models = GPT4All.list_models()

        await call.message.edit_text("–£–¥–∞—á–∞ ‚úÖ\n"
                                     "–í—ã —Ç–µ–ø–µ—Ä—å –º–æ–∂–µ—Ç–µ —Å–ø–æ–∫–æ–π–Ω–æ –≤–µ—Å—Ç–∏ –¥–∏–∞–ª–æ–≥ ü§ñ\n"
                                     f"–í—ã –≤—ã–±—Ä–∞–ª–∏ –º–æ–¥–µ–ª—å <b>{models[callback_data.index]['name']}</b>üëæ –æ—Ç Gpt4All\n"
                                     "–ß—Ç–æ–±—ã –ø—Ä–µ–∫—Ä–∞—Ç–∏—Ç—å –æ–±—â–µ–Ω–∏–µ, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ /cancel ",
                                     reply_markup=delete_keyboard(admin_id=callback_data.user_id))

    generative_functions = {
        # Format is social_network_name: generative_function
        "telegram": generate_telegram
    }
    handlers_functions = {
        "telegram": [
            [telegram_g4a_handler, [TextToText.filter(F.category_name == "Gpt4All")]],
            [telegram_g4a_infomration_handler, [Gpt4AllModel.filter()]],
            [telegram_g4a_selected_handler, [Gpt4AllSelect.filter()]],
        ]
    }
    category_of_generation: str = "text2text"
    name_of_generation: str = "Gpt4All"
